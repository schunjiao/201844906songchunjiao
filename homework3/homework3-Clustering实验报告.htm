<html>

<head>
<meta http-equiv=Content-Type content="text/html; charset=gb2312">
<meta name=Generator content="Microsoft Word 15 (filtered)">
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:宋体;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"Cambria Math";
	panose-1:0 0 0 0 0 0 0 0 0 0;}
@font-face
	{font-family:等线;
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@等线";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
@font-face
	{font-family:"\@宋体";
	panose-1:2 1 6 0 3 1 1 1 1 1;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{margin:0cm;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	font-size:10.5pt;
	font-family:等线;}
p.MsoHeader, li.MsoHeader, div.MsoHeader
	{mso-style-link:"页眉 字符";
	margin:0cm;
	margin-bottom:.0001pt;
	text-align:center;
	layout-grid-mode:char;
	border:none;
	padding:0cm;
	font-size:9.0pt;
	font-family:等线;}
p.MsoFooter, li.MsoFooter, div.MsoFooter
	{mso-style-link:"页脚 字符";
	margin:0cm;
	margin-bottom:.0001pt;
	layout-grid-mode:char;
	font-size:9.0pt;
	font-family:等线;}
pre
	{mso-style-link:"HTML 预设格式 字符";
	margin:0cm;
	margin-bottom:.0001pt;
	font-size:12.0pt;
	font-family:宋体;}
p.MsoListParagraph, li.MsoListParagraph, div.MsoListParagraph
	{margin:0cm;
	margin-bottom:.0001pt;
	text-align:justify;
	text-justify:inter-ideograph;
	text-indent:21.0pt;
	font-size:10.5pt;
	font-family:等线;}
span.a
	{mso-style-name:"页眉 字符";
	mso-style-link:页眉;}
span.a0
	{mso-style-name:"页脚 字符";
	mso-style-link:页脚;}
span.HTML
	{mso-style-name:"HTML 预设格式 字符";
	mso-style-link:"HTML 预设格式";
	font-family:宋体;}
.MsoChpDefault
	{font-family:等线;}
 /* Page Definitions */
 @page WordSection1
	{size:595.3pt 841.9pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	layout-grid:15.6pt;}
div.WordSection1
	{page:WordSection1;}
 /* List Definitions */
 ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
-->
</style>

</head>

<body lang=ZH-CN style='text-justify-trim:punctuation'>

<div class=WordSection1 style='layout-grid:15.6pt'>

<p class=MsoNormal align=center style='text-align:center'><b><span lang=EN-US
style='font-size:18.0pt'>Data Mining</span></b><b><span style='font-size:18.0pt'>实验报告</span></b></p>

<p class=MsoNormal align=center style='text-align:center'><b><span lang=EN-US
style='font-size:16.0pt'>Homework 3</span></b><b><span style='font-size:16.0pt'>：<span
lang=EN-US>clustering</span></span></b></p>

<p class=MsoNormal align=center style='text-align:center'><span
style='font-size:14.0pt'>学号：<span lang=EN-US>201844906&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>姓名：宋春娇</span></p>

<p class=MsoNormal align=center style='text-align:center'><span lang=EN-US
style='font-size:16.0pt'>&nbsp;</span></p>

<p class=MsoListParagraph style='margin-left:36.0pt;text-indent:-36.0pt'><span
lang=EN-US style='font-size:15.0pt'>一、<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:15.0pt'>实验要求</span></p>

<p class=MsoListParagraph style='margin-left:60.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⒈<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:12.0pt'>测试<span lang=EN-US>sklearn</span>中聚类算法在数据集上的聚类效果；</span></p>

<p class=MsoListParagraph style='margin-left:60.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⒉<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:12.0pt'>使用<span lang=EN-US>NMI(Normalized
Mutual Information)</span>作为评价指标。</span></p>

<p class=MsoListParagraph style='margin-left:36.0pt;text-indent:-36.0pt'><span
lang=EN-US style='font-size:15.0pt'>二、<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:15.0pt'>数据集</span></p>

<p class=MsoListParagraph style='margin-left:39.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>1、<span style='font:7.0pt "Times New Roman"'>&nbsp;
</span></span><span style='font-size:12.0pt'>数据集<span lang=EN-US>Tweets</span>以<span
lang=EN-US>Json</span>格式存储数据，格式如下：<span lang=EN-US>{&quot;text&quot;: &quot;centrepoint
winter white gala london&quot;, &quot;cluster&quot;: 65}</span>。需要将其进行预处理，将文本和<span
lang=EN-US>label</span>存储在列表中，然后对文本进行分词处理，后续算法会用到<span lang=EN-US>tf_idf</span>矩阵，可以用过<span
lang=EN-US>sklearn</span>中的<span lang=EN-US>TfidfVectorizer</span>方法得到。</span></p>

<p class=MsoListParagraph style='margin-left:36.0pt;text-indent:-36.0pt'><span
lang=EN-US style='font-size:15.0pt'>三、<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:15.0pt'>实验过程</span></p>

<p class=MsoListParagraph style='margin-left:60.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⒈<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:12.0pt'>安装<span lang=EN-US>sklearn</span></span></p>

<p class=MsoListParagraph style='margin-left:60.0pt;text-indent:0cm'><span
style='font-size:12.0pt'>使用<span lang=EN-US>pip install</span>命令进行安装，安装<span
lang=EN-US>sklearn</span>模块之前要确保已经安装了<span lang=EN-US>numpy</span>和<span
lang=EN-US>scipy</span>。</span></p>

<p class=MsoListParagraph style='margin-left:60.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⒉<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:12.0pt'>对于实验要求指定的<span lang=EN-US>8</span>种算法，通过<span
lang=EN-US>scikit-learn</span>官方文档进行学习，通过文档以及示例熟悉<span lang=EN-US>8</span>种算法的使用方法。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑴<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>K-Means</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.1pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>算法的目的是将<span lang=EN-US>n</span>个向量分别归属到<span
lang=EN-US>K</span>个中心点里面去。算法首先会随机选择<span lang=EN-US>K</span>个中心向量，然后通过迭代计算以及重新选择<span
lang=EN-US>K</span>个中心向量，使得<span lang=EN-US>n</span>个向量各自被分配到距离最近的<span
lang=EN-US>K</span>中心点，并且所有向量距离各自中心点的和最小。</span></p>

<p class=MsoListParagraph style='margin-left:81.1pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>值得注意的是：有两个地方是需要算法使用者去自己选择的：第一个就是<span lang=EN-US>K</span>的值，简而言之就是数据集应该被分成多少个类，在<span
lang=EN-US>K-Means</span>算法里面是要求先给出<span lang=EN-US>K</span>值的<span lang=EN-US>;
</span>第二个就是距离函数，即如何计算向量和向量或者向量和中心点之间的距离，最常见的自然是欧式距离，也可以用余弦相似度来作为距离函数。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑵<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>Affinity Propagation</span><span
style='font-size:12.0pt'>（<span lang=EN-US>AP</span>近邻传播聚类算法）</span></p>

<p class=MsoListParagraph style='margin-left:81.1pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>思想：根据<span lang=EN-US>n</span>个点之间的相似度进行聚类（相似度可以用两个点之间的欧式距离来衡量）。两个点之间的相似度可以相同也可以不同，构成一个<span
lang=EN-US>n*n</span>的相似度矩阵。该算法不需要事先指定聚类数目，它将所有的数据点都作为潜在的聚类中心。</span></p>

<p class=MsoListParagraph style='margin-left:81.1pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>以<span lang=EN-US>S</span>矩阵的对角线上的数值<span lang=EN-US>s
(k, k)</span>作为<span lang=EN-US>k</span>点能否成为聚类中心的评判标准<span lang=EN-US>,</span>这意味着该值越大<span
lang=EN-US>,</span>这个点成为聚类中心的可能性也就越大<span lang=EN-US>,</span>这个值又称作参考度<span
lang=EN-US>p ( preference) </span>。聚类的数量受到参考度<span lang=EN-US>p</span>的影响<span
lang=EN-US>,</span>如果认为每个数据点都有可能作为聚类中心<span lang=EN-US>,</span>那么<span
lang=EN-US>p</span>就应取相同的值。如果取输入的相似度的均值作为<span lang=EN-US>p</span>的值<span
lang=EN-US>,</span>得到聚类数量是中等的。如果取最小值<span lang=EN-US>,</span>得到类数较少的聚类。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑶<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>MeanShift</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>算法原理：在<span lang=EN-US>n</span>个数据点中随机选择一个点作为圆心，找出距离圆心小于等于<span
lang=EN-US>bandwidth</span>的所有点（即以该点为圆心，以<span lang=EN-US>bandwidth</span>为半径的园内所有点），这些点属于和圆心相同类别的概率要<span
lang=EN-US>+1</span>，然后计算出一个漂移向量，使圆沿着漂移向量移动，移动后的圆重复概率<span lang=EN-US>+1</span>操作。直至所有的点均被标记类别。漂移向量的计算方法是将园内所有点到圆心的向量之和。这使得圆会向着点密集区域移动。也可以理解成该算法是沿着密度上升的方向寻找属于一个簇的点。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:0cm'><span
style='font-size:12.0pt'>编程过程中将<span lang=EN-US>tfidf_matrix</span>作为参数传递时会报如下错误：<span
lang=EN-US>TypeError: A sparse matrix was passed, but dense data is required.
Use X.toarray() to convert to a dense numpy array.</span>于是将参数改为<span
lang=EN-US>tfidf_matrix.toarray()</span>。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑷<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>spectral_clustering</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:0cm'><span
style='font-size:12.0pt'>它是一种基于图论的聚类方法（这点上跟<span lang=EN-US>AP</span>类似，而<span
lang=EN-US>K-Means</span>是基于点与点的距离计算），它能够识别任意形状的样本空间且收敛于全局最有解，其基本思想是利用样本数据的相似矩阵进行特征分解后得到的特征向量进行聚类。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑸<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>agglomerative_clustering</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>凝聚是一开始将每个样本当做一个聚类，接着通过计算将距离最近的两个聚类合并，成为新聚类，每次合并聚类总数减少一个，不断循环合并操作，直到所有聚类合并成一个聚类或当聚类数量到达某预定值或当聚类直接距离达到某阀值后停止合并。而分裂则与凝聚相反，一开始将所有样本当做一个聚类，每次分裂一个聚类，直到满足某条件。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑹<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>GaussianMixture</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>混合高斯模型是用高斯概率密度函数（正态分布曲线）精确地量化事物，将一个事物分解为若干的基于高斯概率密度函数（正态分布曲线）形成的模型。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑺<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>DBSCAN</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:24.0pt'><span
style='font-size:12.0pt'>基于密度的方法的特点是不依赖于距离，而是依赖于密度，从而克服基于距离的算法只能发现“球形”聚簇的缺点。 </span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:0cm'><span
lang=EN-US style='font-size:12.0pt'>&nbsp;DBSCAN</span><span style='font-size:
12.0pt'>的核心思想是从某个核心点出发，不断向密度可达的区域扩张，从而得到一个包含核心点和边界点的最大化区域，区域中任意两点密度相连。就是我们先找到一个核心对象，从它出发，确定若干个直接密度可达的对象，再从这若干个对象出发，寻找它们直接密度可达的点，直至最后没有可添加的对象了，那么一个簇的更新就完成了。我们也可以说，簇其实就是所有密度可达的点的集合。</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:-18.0pt'><span
lang=EN-US style='font-size:12.0pt'>⑻<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span lang=EN-US style='font-size:12.0pt'>birch</span><span
style='font-size:12.0pt'>算法</span></p>

<p class=MsoListParagraph style='margin-left:81.0pt;text-indent:0cm'><span
lang=EN-US style='font-size:12.0pt'>BIRCH</span><span style='font-size:12.0pt'>算法利用了一个树结构来帮助我们快速的聚类，这个数结构类似于平衡<span
lang=EN-US>B+</span>树，一般将它称之为聚类特征树<span lang=EN-US>(Clustering Feature Tree</span>，简称<span
lang=EN-US>CF Tree)</span>。这颗树的每一个节点是由若干个聚类特征<span lang=EN-US>(Clustering
Feature</span>，简称<span lang=EN-US>CF)</span>组成。聚类特征树中，每个节点包括叶子节点都有若干个<span
lang=EN-US>CF</span>，而内部节点的<span lang=EN-US>CF</span>有指向孩子节点的指针，所有的叶子节点用一个双向链表链接起来。</span></p>

<p class=MsoListParagraph style='margin-left:36.0pt;text-indent:-36.0pt'><span
lang=EN-US style='font-size:15.0pt'>四、<span style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;
</span></span><span style='font-size:15.0pt'>实验结果</span></p>

<p class=MsoListParagraph style='margin-left:36.0pt;text-indent:0cm'><span
lang=EN-US><img width=554 height=147 id="图片 1"
src="homework3-Clustering实验报告.files/image001.jpg"></span></p>

</div>

</body>

</html>
